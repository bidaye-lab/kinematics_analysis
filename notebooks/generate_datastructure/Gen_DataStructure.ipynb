{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from natsort import os_sorted\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1648c83c",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91314077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract folders for each dataset\n",
    "def extract_folders(anipose_folders_path, exception):\n",
    "    # extract folders with 3d position data\n",
    "\n",
    "    print(\"------------------Step1 : Extracting CSV file paths------------------\")\n",
    "\n",
    "    ballpos_folders_path = Path(str(anipose_folders_path) + \"\\\\BallPos\")\n",
    "    if os.path.exists(ballpos_folders_path):\n",
    "        print(\"INFO : BallPos folder found in project\")\n",
    "    else:\n",
    "        raise TypeError(\"No BallPos subfoldder found in project\")\n",
    "    \n",
    "    ballvel_folders_path = Path(str(anipose_folders_path) + \"\\\\BallVel\")\n",
    "    if os.path.exists(ballvel_folders_path):\n",
    "        print(\"INFO : BallVel folder found\")\n",
    "    else:\n",
    "        raise TypeError(\"No BallPos subfoldder found in project\")\n",
    "\n",
    "    pos_folders = []\n",
    "    for i in anipose_folders_path.glob('*\\\\pose-3d\\\\*.csv'):\n",
    "        if len(exception) != 0:\n",
    "            if str(i).split(\"\\\\\")[-3] in exception:\n",
    "                continue\n",
    "            else:    \n",
    "                pos_folders.append(i)\n",
    "        else:\n",
    "            pos_folders.append(i)\n",
    "\n",
    "    pos_folders = os_sorted(pos_folders)\n",
    "    \n",
    "    # extract folders with angle data\n",
    "    angle_folders = []\n",
    "    for i in anipose_folders_path.glob('*\\\\angles\\\\*.csv'):\n",
    "        if len(exception) != 0:\n",
    "            if str(i).split(\"\\\\\")[-3] in exception:\n",
    "                continue\n",
    "            else:    \n",
    "                angle_folders.append(i)\n",
    "        else:\n",
    "            angle_folders.append(i)\n",
    "\n",
    "    angle_folders = os_sorted(angle_folders)\n",
    "    \n",
    "    # extract folders with ball position data\n",
    "    ballpos_folders = []\n",
    "    for i in ballpos_folders_path.glob('*.csv'):\n",
    "        if len(exception) != 0:\n",
    "            if str(i).split(\"\\\\\")[-1][:len(str(i).split(\"\\\\\")[-1]) - 11] in exception:\n",
    "                continue\n",
    "            else:    \n",
    "                ballpos_folders.append(i)\n",
    "        else:\n",
    "            ballpos_folders.append(i)\n",
    "\n",
    "    ballpos_folders = os_sorted(ballpos_folders)\n",
    "    \n",
    "    # extract folders with ball velocity data\n",
    "    ballvel_folders = []\n",
    "    for i in ballvel_folders_path.glob('*.csv'):\n",
    "        if len(exception) != 0:\n",
    "            if str(i).split(\"\\\\\")[-1][:len(str(i).split(\"\\\\\")[-1]) - 11] in exception:\n",
    "                continue\n",
    "            else:    \n",
    "                ballvel_folders.append(i)\n",
    "        else:\n",
    "            ballvel_folders.append(i)\n",
    "\n",
    "    ballvel_folders = os_sorted(ballvel_folders)\n",
    "    \n",
    "    \n",
    "    return pos_folders, angle_folders, ballpos_folders, ballvel_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe56b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_dicts (pos3d_dict, angle_dict, ballpos_dict, ballvel_dict):\n",
    "    for fly in pos3d_dict.keys():\n",
    "        len_pose3d = len(pos3d_dict[fly])\n",
    "        len_angle = len(angle_dict[fly])\n",
    "        len_ballpos = len(ballpos_dict[fly])\n",
    "        len_ballvel = len(ballvel_dict[fly])\n",
    "\n",
    "        if len_pose3d  == len_ballpos:\n",
    "            print(\"INFO: All dataframes of equal lengths with complete trials for {flynum}: (pose3d, {xx}) , (angle, {yy}), (ballpos, {zz}), (ballvel, {aa})\".format(flynum = fly, xx = len(pos3d_dict[fly]), yy= len(angle_dict[fly]), zz =len(ballpos_dict[fly]) , aa = len(ballvel_dict[fly])))\n",
    "            continue\n",
    "        elif len_pose3d > len_ballpos:\n",
    "            print(\"INFO: Extra frames found in pose_3d for {flynum}. Reducing frame number to match ball pos\".format(flynum = fly))\n",
    "            ## reduce frame number of pose3d and angle \n",
    "            new_pose3d = pos3d_dict[fly].iloc[:len_ballpos,:]\n",
    "            new_angle = angle_dict[fly].iloc[:len_ballpos,:]\n",
    "\n",
    "            if len(new_pose3d)%1400 == 0:\n",
    "                pos3d_dict.update({fly:new_pose3d})\n",
    "                angle_dict.update({fly:new_angle})\n",
    "                print( \"INFO: All dataframes updated for {flynum}: (pose3d, {xx}) , (angle, {yy}), (ballpos, {zz}), (ballvel, {aa})\".format(flynum = fly, xx = len(pos3d_dict[fly]), yy= len(angle_dict[fly]), zz =len(ballpos_dict[fly]) , aa = len(ballvel_dict[fly])))\n",
    "\n",
    "            else:\n",
    "                \n",
    "                diff = len(new_pose3d)%1400 ## frames to remove from all dfs for fly\n",
    "                print(\"INFO: Incomplete data structure for {flynum}. Removing last {num} frames\".format(flynum = fly, num = diff))\n",
    "\n",
    "                updated_pose3d = new_pose3d.iloc[:-diff, :]\n",
    "                updated_angle = new_angle[fly].iloc[:-diff, :]\n",
    "                updated_ballpos = ballpos_dict[fly].iloc[:-diff, :]\n",
    "                updated_ballvel = ballvel_dict[fly].iloc[:-diff, :]\n",
    "\n",
    "                pos3d_dict.update({fly:updated_pose3d})\n",
    "                angle_dict.update({fly:updated_angle})\n",
    "                ballpos_dict.update({fly:updated_ballpos})\n",
    "                ballvel_dict.update({fly:updated_ballvel})\n",
    "\n",
    "                print( \"INFO: All dataframes updated for {flynum}: (pose3d, {xx}) , (angle, {yy}), (ballpos, {zz}), (ballvel, {aa})\".format(flynum = fly, xx = len(pos3d_dict[fly]), yy= len(angle_dict[fly]), zz =len(ballpos_dict[fly]) , aa = len(ballvel_dict[fly])))\n",
    "        else: ## len_pose3d < len_ballpos\n",
    "            print(\"INFO: Extra frames found in ballpos for {flynum}. Reducing frame number to match pose 3d\".format(flynum = fly))\n",
    "            ## reduce frame number of ballpos and ballvel \n",
    "            new_ballpos = ballpos_dict[fly].iloc[:len_pose3d,:]\n",
    "            new_ballvel = ballvel_dict[fly].iloc[:len_pose3d,:]\n",
    "            \n",
    "            if len(new_ballpos)%1400 == 0:\n",
    "                ballpos_dict.update({fly:new_ballpos})\n",
    "                ballvel_dict.update({fly:new_ballvel})\n",
    "                print( \"INFO: All dataframes updated for {flynum}: (pose3d, {xx}) , (angle, {yy}), (ballpos, {zz}), (ballvel, {aa})\".format(flynum = fly, xx = len(pos3d_dict[fly]), yy= len(angle_dict[fly]), zz =len(ballpos_dict[fly]) , aa = len(ballvel_dict[fly])))\n",
    "            else:\n",
    "                diff = len_pose3d%1400 ## frames to remove from all dfs for fly\n",
    "                print(\"INFO: Incomplete data structure for {flynum}. Removing last {num} frames\".format(flynum = fly, num = diff))\n",
    "\n",
    "                updated_pose3d = pos3d_dict[fly].iloc[:-diff, :]\n",
    "                updated_angle = angle_dict[fly].iloc[:-diff, :]\n",
    "                updated_ballpos = new_ballpos.iloc[:-diff, :]\n",
    "                updated_ballvel = new_ballvel.iloc[:-diff, :]\n",
    "\n",
    "                pos3d_dict.update({fly:updated_pose3d})\n",
    "                angle_dict.update({fly:updated_angle})\n",
    "                ballpos_dict.update({fly:updated_ballpos})\n",
    "                ballvel_dict.update({fly:updated_ballvel})\n",
    "\n",
    "                print( \"INFO: All dataframes updated for {flynum}: (pose3d, {xx}) , (angle, {yy}), (ballpos, {zz}), (ballvel, {aa})\".format(flynum = fly, xx = len(pos3d_dict[fly]), yy= len(angle_dict[fly]), zz =len(ballpos_dict[fly]) , aa = len(ballvel_dict[fly])))\n",
    "    return pos3d_dict, angle_dict, ballpos_dict, ballvel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_df (dict):\n",
    "    df = pd.DataFrame()\n",
    "    for fly in dict.keys():\n",
    "        data = dict[fly]\n",
    "        df = pd.concat([df, data], ignore_index= True).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(pos_folders, angle_folders, ballpos_folders, ballvel_folders):\n",
    "    \"\"\"extract position, angle, ball velocity and ball position data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pos_folders : list\n",
    "        anipose 3d pose csv file paths\n",
    "    angle_folders : list\n",
    "        anipose angle csv file paths\n",
    "    ballpos_folders : list\n",
    "        ball pos csv file paths\n",
    "    ballvel_folders : list\n",
    "        ball velocity csv file paths\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"------------------Step2 : Extracting data from CSV files to DataFrames------------------\")\n",
    "\n",
    "    indent = \" \"*6\n",
    "\n",
    "    pos3d_dict = {}\n",
    "    for data_csv in pos_folders:\n",
    "        num = str(data_csv).split(\"\\\\\")[-3][:]\n",
    "        temp_csv = pd.read_csv(data_csv)\n",
    "        temp_csv = temp_csv.iloc[:, :-13] # remove last 13 columns of anipose metadata\n",
    "        pos3dclean_df = pd.DataFrame()\n",
    "        for item in np.arange(0,len(temp_csv.columns),6):\n",
    "            pos3dclean_df = pd.concat([pos3dclean_df, temp_csv.iloc[:,item:item+3]],axis=1) \n",
    "        pos3d_dict.update({str(num) :pos3dclean_df })\n",
    "\n",
    "    \n",
    "    angle_dict = {}\n",
    "\n",
    "    for data_csv in angle_folders:\n",
    "        num = str(data_csv).split(\"\\\\\")[-3][:]\n",
    "        temp_csv = pd.read_csv(data_csv)\n",
    "        angle_dict.update({str(num) :temp_csv })\n",
    "\n",
    "    \n",
    "    ballpos_dict = {}\n",
    "\n",
    "    for data_csv in ballpos_folders:\n",
    "        num = str(data_csv).split(\"\\\\\")[-1][:-11]\n",
    "        temp_csv = pd.read_csv(data_csv)\n",
    "        temp_len = len(temp_csv)\n",
    "\n",
    "        if temp_len%1400 !=0:\n",
    "            L = temp_len\n",
    "            missing = 1400 - L%1400 \n",
    "            print(\"INFO: Missing frames found in {filepath}, missing count = {frames}\".format(filepath = data_csv, frames = missing))\n",
    "            print(indent +'Info: length before:', L)\n",
    "            extra = pd.DataFrame([])\n",
    "            for i in range(1400-L%1400):\n",
    "                extra = pd.concat([extra,pd.DataFrame([np.nan, np.nan, np.nan]).T ], axis =0)\n",
    "#             print('dim extra = ', len(extra.columns))   \n",
    "            extra.columns = data_csv.columns.tolist()\n",
    "            temp_csv = pd.concat([temp_csv, extra], axis = 0, ignore_index=True)\n",
    "            temp_csv.columns = [\"x_pos\", \"y_pos\", \"z_pos\"]\n",
    "            print(indent +'Info: length after:', len(temp_csv))\n",
    "        \n",
    "        ballpos_dict.update({str(num) :temp_csv })\n",
    "            \n",
    "\n",
    "    \n",
    "    ballvel_dict = {}\n",
    "    for data_csv in ballvel_folders:\n",
    "        num = str(data_csv).split(\"\\\\\")[-1][:-11]\n",
    "        temp_csv = pd.read_csv(data_csv)\n",
    "        temp_len = len(temp_csv)\n",
    "\n",
    "        if temp_len%1400 !=0:\n",
    "            L = temp_len\n",
    "            missing = 1400 - L%1400 \n",
    "            print(\"INFO: Missing frames found in {filepath}, missing count = {frames}\".format(filepath = data_csv, frames = missing))\n",
    "            print(indent +'Info: length before:', L)\n",
    "            extra = pd.DataFrame([])\n",
    "            for i in range(1400-L%1400):\n",
    "                extra = pd.concat([extra,pd.DataFrame([np.nan, np.nan, np.nan]).T ], axis =0)\n",
    "            extra.columns = data_csv.columns.tolist()\n",
    "            temp_csv = pd.concat([temp_csv,extra], axis = 0, ignore_index=True)\n",
    "            print(indent +'Info: length after:', len(temp_csv))\n",
    "            temp_csv.columns = [\"x_vel\", \"y_vel\", \"z_vel\"]\n",
    "        ballvel_dict.update({str(num) :temp_csv })\n",
    "        \n",
    "\n",
    "\n",
    "    print(\"INFO: Finished extracting dataframes with 3d pose, angles, ballpos and ballvel data\")\n",
    "    pos3d_dict, angle_dict, ballpos_dict, ballvel_dict = clean_all_dicts (pos3d_dict, angle_dict, ballpos_dict, ballvel_dict)\n",
    "    \n",
    "\n",
    "    return pos3d_dict, angle_dict, ballpos_dict, ballvel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd899c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_initcol(pos3d_dict,  SF_path = None):\n",
    "    \"\"\"extract information about fly number, trial number, frame number, and stimulation frequency if SF_path is defined\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pos3d_dict : dict\n",
    "        dict with flynumbers as keys with 3D pose data\n",
    "    SF_path : Path, optional\n",
    "        Path to CSV file with stim parameter, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        DF with flynum, tnum, fnum, SF (optional)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"------------------Step3 : Extracting Metadata columns------------------\")\n",
    "    \n",
    "    indent = \" \"*6\n",
    "    \n",
    "    if SF_path != None:\n",
    "        SF = pd.read_csv(SF_path)\n",
    "        print(\"INFO : SF path found!\")\n",
    "    else:\n",
    "        SF = []\n",
    "        print(\"INFO : NO SF path found!!\")\n",
    "\n",
    "    \n",
    "    trial_len = 1400\n",
    "    Init_cols_all = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for fly in pos3d_dict.keys():\n",
    "        data = pos3d_dict[fly]\n",
    "        data_len = int(len(data))\n",
    "\n",
    "        list = [x for x in fly if x != 'N']\n",
    "        flynum = ''\n",
    "        for i in list:\n",
    "            flynum = flynum + i\n",
    "        flynum = int(flynum)\n",
    "\n",
    "        flynum_list = [flynum] * data_len ## flynum list created\n",
    "\n",
    "        tot_trials = int(data_len / trial_len)\n",
    "        tnum_range = [x for x in range(1,tot_trials+1)]\n",
    "        tnum_list = []\n",
    "        for i in tnum_range:\n",
    "            temp_tnum = [i]*trial_len\n",
    "            tnum_list = tnum_list + temp_tnum ## tnum list created\n",
    "        \n",
    "        fnum_list = [x for x in range(data_len)] ## fnum list created\n",
    "        \n",
    "        if len(flynum_list) == len(tnum_list) == len(fnum_list):\n",
    "            print(indent + \"INFO:flynum, tnum, fnum arrays created for {fly}\".format(fly = fly))\n",
    "        else:\n",
    "            raise TypeError(\"INFO: flynum, tnum,fnum array lengths don't match for {fly}\".format(fly = fly))\n",
    "    \n",
    "        \n",
    "        init_cols = pd.DataFrame([flynum_list, tnum_list, fnum_list]).T\n",
    "        init_cols.columns = ['flynum', 'tnum', 'fnum']\n",
    "        init_cols.reset_index(drop=True)\n",
    "\n",
    "        if len(SF) > 0:\n",
    "            SF_fly = SF[fly][:tot_trials].tolist()\n",
    "            SF_list= []\n",
    "            for i in SF_fly:\n",
    "                temp_sf = [i]*trial_len\n",
    "                SF_list = SF_list + temp_sf   ## SF list created\n",
    "            \n",
    "            init_cols = pd.concat([init_cols, pd.DataFrame(SF_list)], axis = 1)\n",
    "            init_cols.columns = ['flynum', 'tnum', 'fnum', 'SF']\n",
    "            init_cols.reset_index(drop=True)\n",
    "            \n",
    "            Init_cols_all = pd.concat([Init_cols_all, init_cols], axis = 0).reset_index(drop=True)\n",
    "        else:\n",
    "            Init_cols_all = pd.concat([Init_cols_all, init_cols], axis = 0).reset_index(drop=True)\n",
    "\n",
    "    return Init_cols_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_flydata(anipose_folders_path, exception, SF_path = None):\n",
    "    \n",
    "\n",
    "    pos_folders, angle_folders, ballpos_folders, ballvel_folders = extract_folders(anipose_folders_path, exception)\n",
    "    pos3d_dict, angle_dict, ballpos_dict, ballvel_dict = extract_data(pos_folders, angle_folders, ballpos_folders, ballvel_folders)\n",
    "    \n",
    "    Init_cols_all= extract_initcol(pos3d_dict, SF_path)\n",
    "\n",
    "    pos3d_df = dict_to_df (pos3d_dict)\n",
    "    angle_df = dict_to_df (angle_dict)\n",
    "    ballpos_df = dict_to_df (ballpos_dict)\n",
    "    ballvel_df = dict_to_df (ballvel_dict)\n",
    "\n",
    "    fly_data = pd.concat([Init_cols_all, pos3d_df, angle_df, ballpos_df, ballvel_df], axis=1)\n",
    "    \n",
    "    print(\"INFO: All Dataframes combined sucessfully\")\n",
    "    return fly_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table(all_data):\n",
    "    gen_df = pd.DataFrame()\n",
    "    for genotype in all_data.keys():\n",
    "        fly_data = all_data[genotype]\n",
    "        gendata = {\"Genotype\": genotype, \"no. of flies\": [max(fly_data[\"flynum\"])], \"flydata\": [fly_data]}\n",
    "        temp_df = pd.DataFrame(data=gendata)\n",
    "        gen_df = pd.concat([gen_df, temp_df], axis=0)\n",
    "    return gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_prestim_vel (dataframe, threhsold):\n",
    "    threshold = int(threhsold)\n",
    "    filtered_df = pd.DataFrame()\n",
    "    for n in dataframe['flynum'].unique().tolist():\n",
    "        for t in dataframe.groupby('flynum').get_group(n)['tnum'].unique().tolist():\n",
    "            data = dataframe.groupby('flynum').get_group(n).groupby('tnum').get_group(t)\n",
    "            mean_vel = np.mean(data.loc[(data['fnum']%1400>320)&(data['fnum']%1400<400)]['x_vel'])\n",
    "            if mean_vel >=threshold:\n",
    "                filtered_df = pd.concat([filtered_df.reset_index(drop=True), data.reset_index(drop=True)], axis = 0)\n",
    "    return filtered_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02d4921d",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d3eaf35",
   "metadata": {},
   "source": [
    "## Define genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b92c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop1- set1 : N1- N6\n",
    "test_anipose_folders_path = Path(r'Z:\\BallSystem_AniposeReconstructions\\3_BPN-S1-Activation\\newCalib_flybased\\project') ## path to the anipose project folder\n",
    "test_SF_path = Path(r\"Z:\\BallSystem_AniposeReconstructions\\3_BPN-S1-Activation\\newCalib_flybased\\project\\BPN-S1_Metadata_Freq.csv\") # path to the csv file with the frequency of activation \n",
    "test_exception = [] # if any fly needs to be excluded (eg: N1), enter as 'N1'\n",
    "test_data = combine_flydata(test_anipose_folders_path, test_exception, test_SF_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c158ced0",
   "metadata": {},
   "source": [
    "## Create table with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93550387",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {\"test_genotype\": test_data}\n",
    "\n",
    "gen_df = generate_table(all_data)\n",
    "gen_df.reset_index(drop=True, inplace=True)\n",
    "display(gen_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5983eb10",
   "metadata": {},
   "source": [
    "Save DataStructure as HDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_df.to_hdf(Path(r'C:\\LabGit\\test_datastructure.h5'), key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598cccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d85e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
